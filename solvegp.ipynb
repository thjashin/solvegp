{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOLVE-GP: A Toy Example\n",
    "\n",
    "The aim of this example is to illustrate the training process of SOLVE-GP.\n",
    "The ideal use case of the algorithm should be large-scale applications where the number of inducing points is limited by the computational budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsVT5WvEyGin"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/session_manager.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/session_manager.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/misc.py:27: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/misc.py:27: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/training/tensorflow_optimizer.py:156: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/training/tensorflow_optimizer.py:156: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/saver/coders.py:80: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/saver/coders.py:80: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['PATH'] = os.environ['PATH'] + ':/usr/local/texlive/2019/bin/x86_64-darwin'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gpflow\n",
    "from gpflow import settings, features, transforms, kullback_leiblers\n",
    "from gpflow.params import Parameter, Minibatch, DataHolder\n",
    "from gpflow.conditionals import Kuu, Kuf\n",
    "from gpflow.decors import autoflow\n",
    "from scipy.cluster.vq import kmeans2\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"pgf\")\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import rc\n",
    "from matplotlib.backends.backend_pgf import FigureCanvasPgf\n",
    "mpl.backend_bases.register_backend('pdf', FigureCanvasPgf)\n",
    "rc('text', usetex=True)\n",
    "rc(\"pgf\", rcfonts=False, preamble=r'\\usepackage{color}')\n",
    "tf.set_random_seed(1234)\n",
    "np.random.seed(1234)\n",
    "import imageio\n",
    "import moviepy.editor as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the SOLVE-GP algorithm as a GPflow class. Please use GPflow version 1.5.1 and Tensorflow 1.x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOLVEGP(gpflow.models.GPModel):\n",
    "    def __init__(self, X, Y, kern, likelihood, z, a,\n",
    "                 mean_function=None,\n",
    "                 num_outputs=None,\n",
    "                 whiten=True,\n",
    "                 minibatch_size=None,\n",
    "                 num_data=None,\n",
    "                 **kwargs):\n",
    "        # sort out the X, Y into MiniBatch objects if required.\n",
    "        if minibatch_size is None:\n",
    "            X = DataHolder(X)\n",
    "            Y = DataHolder(Y)\n",
    "        else:\n",
    "            X = Minibatch(X, batch_size=minibatch_size, seed=0)\n",
    "            Y = Minibatch(Y, batch_size=minibatch_size, seed=0)\n",
    "\n",
    "        # init the super class, accept args\n",
    "        gpflow.models.GPModel.__init__(\n",
    "            self, X, Y, kern, likelihood, mean_function, num_outputs, **kwargs)\n",
    "        self.num_outputs = num_outputs\n",
    "        self.num_data = num_data or X.shape[0]\n",
    "        self.whiten = whiten\n",
    "\n",
    "        # init variational parameters\n",
    "        self.z = z\n",
    "        self.a = a\n",
    "\n",
    "        with gpflow.params_as_tensors_for(self.z), gpflow.params_as_tensors_for(self.a):\n",
    "            self.Kuu = Kuu(self.z, self.kern, jitter=settings.jitter)\n",
    "            self.Lu = tf.cholesky(self.Kuu)\n",
    "            self.Kvv = Kuu(self.a, self.kern, jitter=settings.jitter)\n",
    "            self.Kuv = self.kern.K(self.z.Z, self.a.Z)\n",
    "        self.Lu_inv_Kuv = tf.matrix_triangular_solve(self.Lu, self.Kuv)\n",
    "        self.Cvv = self.Kvv - tf.matmul(\n",
    "            self.Lu_inv_Kuv, self.Lu_inv_Kuv, transpose_a=True)\n",
    "        self.Lv = tf.cholesky(self.Cvv)\n",
    "\n",
    "        # init variational parameters\n",
    "        M = len(self.z)\n",
    "        with tf.variable_scope(self.name + \"/z\"):\n",
    "            self.qu_mu = Parameter(\n",
    "                np.zeros((M, num_outputs), dtype=settings.float_type), name='qu_mu')\n",
    "            if not self.whiten:\n",
    "                Lu_ = self.enquire_session().run(self.Lu)\n",
    "                qu_sqrt = np.tile(Lu_[None, :, :], [num_outputs, 1, 1])\n",
    "            else:\n",
    "                qu_sqrt = np.tile(np.eye(M, dtype=settings.float_type)[None, :, :], \n",
    "                                    [num_outputs, 1, 1])\n",
    "            self.qu_sqrt = Parameter(\n",
    "                qu_sqrt, transform=transforms.LowerTriangular(M, num_outputs), name='qu_sqrt')\n",
    "\n",
    "        M2 = len(self.a)\n",
    "        with tf.variable_scope(self.name + \"/a\"):\n",
    "            self.qv_mu = Parameter(\n",
    "                np.zeros((M2, num_outputs), dtype=settings.float_type), name='qv_mu')\n",
    "            if not self.whiten:\n",
    "                Lv_ = self.enquire_session().run(self.Lv)\n",
    "                qv_sqrt = np.tile(Lv_[None, :, :], [num_outputs, 1, 1])\n",
    "            else:\n",
    "                qv_sqrt = np.tile(np.eye(M2, dtype=settings.float_type)[None, :, :], \n",
    "                                    [num_outputs, 1, 1])\n",
    "            self.qv_sqrt = Parameter(\n",
    "                qv_sqrt, transform=transforms.LowerTriangular(M2, num_outputs), name='qv_sqrt')\n",
    "    \n",
    "    def kl_u(self):\n",
    "        if self.whiten:\n",
    "            K = None\n",
    "        else:\n",
    "            K = self.Kuu\n",
    "        return kullback_leiblers.gauss_kl(self.qu_mu, self.qu_sqrt, K)\n",
    "\n",
    "    def kl_v(self):\n",
    "        if self.whiten:\n",
    "            K = None\n",
    "        else:\n",
    "            K = self.Cvv\n",
    "        return kullback_leiblers.gauss_kl(self.qv_mu, self.qv_sqrt, K)\n",
    "\n",
    "    @autoflow((settings.float_type, [None, None]))\n",
    "    def predict_f(self, Xnew):\n",
    "        mean_func, fin, fperp, var_in, var_perp = self._build_predict(Xnew)\n",
    "        fmean = fin + fperp + mean_func\n",
    "        fvar = var_in + var_perp\n",
    "        return fmean, fvar\n",
    "    \n",
    "    @autoflow((settings.float_type, [None, None]))\n",
    "    def predict_fin(self, Xnew):\n",
    "        mean_func, fin, fperp, var_in, var_perp = self._build_predict(Xnew)\n",
    "        return fin, var_in\n",
    "\n",
    "    @autoflow((settings.float_type, [None, None]))\n",
    "    def predict_fperp(self, Xnew):\n",
    "        mean_func, fin, fperp, var_in, var_perp = self._build_predict(Xnew)\n",
    "        return fperp, var_perp\n",
    "\n",
    "    @gpflow.params_as_tensors\n",
    "    def build_prior_KL(self):\n",
    "        return self.kl_u() + self.kl_v()\n",
    "\n",
    "    @gpflow.params_as_tensors\n",
    "    def _build_likelihood(self):\n",
    "        KL = self.build_prior_KL()\n",
    "        mean_func, fin, fperp, var_in, var_perp = self._build_predict(\n",
    "            self.X, full_cov=False, full_output_cov=False)\n",
    "        fmean = fin + fperp + mean_func\n",
    "        fvar = var_in + var_perp\n",
    "        var_exp = self.likelihood.variational_expectations(fmean, fvar, self.Y)\n",
    "        scale = tf.cast(self.num_data, settings.float_type) / tf.cast(\n",
    "            tf.shape(self.X)[0], settings.float_type)\n",
    "        likelihood = tf.reduce_sum(var_exp) * scale - KL\n",
    "        return likelihood\n",
    "\n",
    "    @gpflow.params_as_tensors\n",
    "    def _build_predict(self, X, full_cov=False, full_output_cov=False):\n",
    "        Kuf_ = Kuf(self.z, self.kern, X)\n",
    "        Kvf = Kuf(self.a, self.kern, X)\n",
    "        Lu_inv_Kuf = tf.matrix_triangular_solve(self.Lu, Kuf_)\n",
    "        if not self.whiten:\n",
    "            Au = tf.matrix_triangular_solve(\n",
    "                tf.transpose(self.Lu), Lu_inv_Kuf, lower=False)\n",
    "        else:\n",
    "            Au = Lu_inv_Kuf\n",
    "        Cvf = Kvf - tf.matmul(self.Lu_inv_Kuv, Lu_inv_Kuf, transpose_a=True)\n",
    "\n",
    "        if full_cov:\n",
    "            Kff = self.kern.K(X)\n",
    "            Cff = Kff - tf.matmul(Lu_inv_Kuf, Lu_inv_Kuf, transpose_a=True)\n",
    "        else:\n",
    "            Kff = self.kern.Kdiag(X)\n",
    "            Cff = Kff - tf.reduce_sum(tf.square(Lu_inv_Kuf), axis=0)\n",
    "\n",
    "        Lv_inv_Cvf = tf.matrix_triangular_solve(self.Lv, Cvf)\n",
    "        if not self.whiten:\n",
    "            Av = tf.matrix_triangular_solve(\n",
    "                tf.transpose(self.Lv), Lv_inv_Cvf, lower=False)\n",
    "        else:\n",
    "            Av = Lv_inv_Cvf\n",
    "\n",
    "        fin = tf.matmul(Au, self.qu_mu, transpose_a=True)\n",
    "        fperp = tf.matmul(Av, self.qv_mu, transpose_a=True)\n",
    "\n",
    "        # [K, M, M]\n",
    "        Lqu = tf.matrix_band_part(self.qu_sqrt, -1, 0)\n",
    "        Au_tiled = tf.tile(Au[None, ...], [self.num_outputs, 1, 1])\n",
    "        # [K, M, N]\n",
    "        LquTA = tf.matmul(Lqu, Au_tiled, transpose_a=True)\n",
    "        if full_cov:\n",
    "            var_in = tf.matmul(LquTA, LquTA, transpose_a=True)\n",
    "        else:\n",
    "            var_in = tf.reduce_sum(tf.square(LquTA), axis=1)\n",
    "        var_in = tf.transpose(var_in)\n",
    "\n",
    "        Lqv = tf.matrix_band_part(self.qv_sqrt, -1, 0)\n",
    "        Av_tiled = tf.tile(Av[None, ...], [self.num_outputs, 1, 1])\n",
    "        LqvTA = tf.matmul(Lqv, Av_tiled, transpose_a=True)\n",
    "        if full_cov:\n",
    "            var_perp = (tf.matmul(LqvTA, LqvTA, transpose_a=True) + Cff -\n",
    "                        tf.matmul(Lv_inv_Cvf, Lv_inv_Cvf, transpose_a=True))\n",
    "        else:\n",
    "            var_perp = (tf.reduce_sum(tf.square(LqvTA), 1) + Cff -\n",
    "                        tf.reduce_sum(tf.square(Lv_inv_Cvf), 0))\n",
    "        var_perp = tf.transpose(var_perp)\n",
    "        return self.mean_function(X), fin, fperp, var_in, var_perp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g7kJwx6q5uim"
   },
   "outputs": [],
   "source": [
    "class ToyData1D(object):\n",
    "    def __init__(self, train_x, train_y, test_x, normalize=False, \n",
    "                 dtype=np.float64):\n",
    "        self.train_x = np.array(train_x, dtype=dtype)[:, None]\n",
    "        self.train_y = np.array(train_y, dtype=dtype)[:, None]\n",
    "        self.n_train = self.train_x.shape[0]\n",
    "        self.test_x = np.array(test_x, dtype=dtype)[:, None]\n",
    "        self.x_min = np.min(test_x)\n",
    "        self.x_max = np.max(test_x)\n",
    "        self.n_test = self.test_x.shape[0]\n",
    "        if normalize:\n",
    "            self.normalize()\n",
    "\n",
    "    def normalize(self):\n",
    "        self.mean_x = np.mean(self.train_x, axis=0, keepdims=True)\n",
    "        self.std_x = np.std(self.train_x, axis=0, keepdims=True) + 1e-6\n",
    "        self.mean_y = np.mean(self.train_y, axis=0, keepdims=True)\n",
    "        self.std_y = np.std(self.train_y, axis=0, keepdims=True) + 1e-6\n",
    "\n",
    "        for x in [self.train_x, self.test_x]:\n",
    "            x -= self.mean_x\n",
    "            x /= self.std_x\n",
    "\n",
    "        for x in [self.x_min, self.x_max]:\n",
    "            x -= self.mean_x.squeeze()\n",
    "            x /= self.std_x.squeeze()\n",
    "\n",
    "        self.train_y -= self.mean_y\n",
    "        self.train_y /= self.std_y\n",
    "\n",
    "    \n",
    "def load_snelson_data(n=100, dtype=np.float64):\n",
    "    def _load_snelson(filename):\n",
    "        with open(os.path.join(\"data\", \"snelson\", filename), \"r\") as f:\n",
    "            return np.array([float(i) for i in f.read().strip().split(\"\\n\")],\n",
    "                            dtype=dtype)\n",
    "\n",
    "    train_x = _load_snelson(\"train_inputs\")\n",
    "    train_y = _load_snelson(\"train_outputs\")\n",
    "    test_x = _load_snelson(\"test_inputs\")\n",
    "    perm = np.random.permutation(train_x.shape[0])\n",
    "    train_x = train_x[perm][:n]\n",
    "    train_y = train_y[perm][:n]\n",
    "    return ToyData1D(train_x, train_y, test_x=test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy = load_snelson_data(n=100)\n",
    "train_x, train_y = toy.train_x, toy.train_y\n",
    "test_x = toy.test_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 100 training points, 301 test points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iGGld9fdaivF",
    "outputId": "a9e923bd-78c7-4278-ed08-d8bd50ad678f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 1), (100, 1), (301, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize inducing points and optimize the lower bound\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of inducing points\n",
    "M = 5\n",
    "# the number of orthogonal inducing points\n",
    "M2 = 5\n",
    "\n",
    "# training parameters\n",
    "batch_size = 20\n",
    "learning_rate = 0.003\n",
    "n_iters = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run K-means on the training points and use the cluster centers to initialize inducing points. Then the SOLVE-GP lower bound is maximized by the ADAM optimizer. The variational parameters and inducing point locations will be updated by gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-FUjYR8gWxw3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/core/node.py:109: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/core/node.py:109: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/params/parameter.py:388: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/params/parameter.py:388: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/params/parameter.py:394: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/params/parameter.py:394: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/params/dataholders.py:223: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/gpflow/params/dataholders.py:223: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3744: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3744: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n"
     ]
    }
   ],
   "source": [
    "N, x_dim = train_x.shape\n",
    "kernel = gpflow.kernels.RBF(x_dim, ARD=False, name=\"rbf\")\n",
    "likelihood = gpflow.likelihoods.Gaussian(variance=0.1)\n",
    "inducing_points, _ = kmeans2(train_x, M + M2, minit=\"points\")\n",
    "with tf.variable_scope(\"z\"):\n",
    "    z = features.inducingpoint_wrapper(None, inducing_points[:M])\n",
    "with tf.variable_scope(\"a\"):\n",
    "    a = features.inducingpoint_wrapper(None, inducing_points[M:])\n",
    "solvegp = SOLVEGP(train_x, train_y, kernel, likelihood, z, a,\n",
    "                  num_outputs=1, whiten=False, num_data=N, minibatch_size=batch_size)\n",
    "obj = solvegp.objective\n",
    "with gpflow.params_as_tensors_for(likelihood):\n",
    "    likelihood_var = likelihood.variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = solvegp.enquire_session()\n",
    "feed_dict = {} if solvegp.feeds is None else solvegp.feeds\n",
    "opt = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "var_list = list(set(solvegp.trainable_tensors))\n",
    "infer_op = opt.minimize(obj, var_list=var_list)\n",
    "solvegp.initialize(session=sess)\n",
    "sess.run(tf.variables_initializer(var_list=opt.variables()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some plotting code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6_-DI6y8W5dm"
   },
   "outputs": [],
   "source": [
    "def plot_posterior(ax, y_mean, y_var):\n",
    "    y_std = np.sqrt(y_var)\n",
    "    y_upper, y_lower = y_mean + 3 * y_std, y_mean - 3 * y_std\n",
    "    ax.plot(test_x.squeeze(-1), y_mean, c=\"steelblue\", linewidth=2)\n",
    "    ax.fill_between(test_x.squeeze(-1), y_upper.squeeze(-1), y_lower.squeeze(-1),\n",
    "                    alpha=0.5, facecolor=\"lightblue\", lw=0)\n",
    "\n",
    "def setup_axis(ax, title):\n",
    "    ax.set_xlim(test_x.min()+1, test_x.max()-1.5)\n",
    "    ax.set_ylim([-4, 3.5])\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.tick_params(which='both', bottom=False, top=False, labelbottom=False)\n",
    "    ax.set_title(title, fontsize=18)\n",
    "\n",
    "def save_figures(t):\n",
    "    # plot inducing points\n",
    "    with gpflow.params_as_tensors_for(z), gpflow.params_as_tensors_for(a):\n",
    "        Z = sess.run(z.Z).squeeze(-1)\n",
    "        A = sess.run(a.Z).squeeze(-1)\n",
    "\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(8, 6))\n",
    "    gs = gridspec.GridSpec(4, 4, figure=fig)\n",
    "\n",
    "    ax1 = plt.subplot(gs[:2, 1:3])\n",
    "    ax2 = plt.subplot(gs[2:4, :2])\n",
    "    ax3 = plt.subplot(gs[2:4, 2:])\n",
    "\n",
    "    y_mean, y_var = solvegp.predict_f(test_x)\n",
    "    plot_posterior(ax1, y_mean, y_var)\n",
    "    ax1.scatter(Z, np.ones_like(Z)*(-3.5), marker=\"+\", s=100, c=\"k\", linewidths=1.3, label=\"Inducing Points\")\n",
    "    ax1.scatter(A, np.ones_like(A)*(-3.5), marker=\"^\", s=100, facecolor=\"k\", lw=0, label=\"Orthogonal Inducing Points\")\n",
    "    ax1.scatter(train_x.squeeze(-1), train_y.squeeze(-1), facecolor=\"k\", lw=0, s=14)\n",
    "    leg = ax1.legend(fontsize=14, loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=2)\n",
    "    leg_texts = leg.get_texts()\n",
    "    leg_texts[0].set_color(\"b\")\n",
    "    leg_texts[1].set_color(\"r\")\n",
    "    setup_axis(ax1, r\"Posterior Approximation by SOLVE-GP: $p = {\\color{blue} p_\\|} + {\\color{red} p_\\perp}$\")\n",
    "\n",
    "    y_mean, y_var = solvegp.predict_fin(test_x)\n",
    "    plot_posterior(ax2, y_mean, y_var)\n",
    "    ax2.scatter(Z, np.ones_like(Z)*(-3.5), marker=\"+\", s=100, c=\"k\", linewidths=1.3)\n",
    "    setup_axis(ax2, r\"$\\color{blue}f_\\| \\sim p_\\|$\")\n",
    "\n",
    "    y_mean, y_var = solvegp.predict_fperp(test_x)\n",
    "    plot_posterior(ax3, y_mean, y_var)\n",
    "    ax3.scatter(Z, np.ones_like(Z)*(-3.5), marker=\"+\", s=100, c=\"k\", linewidths=1.3)\n",
    "    ax3.scatter(A, np.ones_like(A)*(-3.5), marker=\"^\", s=100, facecolor=\"k\", lw=0)\n",
    "    setup_axis(ax3, r\"$\\color{red}f_\\perp \\sim p_\\perp$\")\n",
    "\n",
    "    plt.savefig(\"results/solvegp-iter-{}.png\".format(t), bbox_inches=\"tight\", dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Then we run the training process. We print values of the lower bound and observation variance during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "KD3CgzmcaEw4",
    "outputId": "ba908e99-746f-48ef-c45e-df07f8f9e2bf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 200, lower bound = -143.3596, obs_var = 0.1358\n",
      "Iter 400, lower bound = -76.0936, obs_var = 0.1457\n",
      "Iter 600, lower bound = -60.2646, obs_var = 0.1455\n",
      "Iter 800, lower bound = -54.9912, obs_var = 0.1414\n",
      "Iter 1000, lower bound = -46.6244, obs_var = 0.1359\n",
      "Iter 1200, lower bound = -37.0410, obs_var = 0.1300\n",
      "Iter 1400, lower bound = -51.8743, obs_var = 0.1241\n",
      "Iter 1600, lower bound = -46.7503, obs_var = 0.1188\n",
      "Iter 1800, lower bound = -54.1932, obs_var = 0.1142\n",
      "Iter 2000, lower bound = -57.4773, obs_var = 0.1103\n",
      "Iter 2200, lower bound = -51.9503, obs_var = 0.1069\n",
      "Iter 2400, lower bound = -55.3193, obs_var = 0.1048\n",
      "Iter 2600, lower bound = -63.9242, obs_var = 0.1030\n",
      "Iter 2800, lower bound = -69.2975, obs_var = 0.1018\n",
      "Iter 3000, lower bound = -28.0195, obs_var = 0.1007\n",
      "Iter 3200, lower bound = -60.6562, obs_var = 0.1000\n",
      "Iter 3400, lower bound = -50.5385, obs_var = 0.0995\n",
      "Iter 3600, lower bound = -41.6798, obs_var = 0.0993\n",
      "Iter 3800, lower bound = -66.5141, obs_var = 0.0988\n",
      "Iter 4000, lower bound = -57.5332, obs_var = 0.0987\n",
      "Iter 4200, lower bound = -46.8940, obs_var = 0.0984\n",
      "Iter 4400, lower bound = -25.0113, obs_var = 0.0990\n",
      "Iter 4600, lower bound = -65.9041, obs_var = 0.0981\n",
      "Iter 4800, lower bound = -53.7044, obs_var = 0.0981\n",
      "Iter 5000, lower bound = -52.4352, obs_var = 0.0979\n",
      "Iter 5200, lower bound = -38.0104, obs_var = 0.0982\n",
      "Iter 5400, lower bound = -60.5478, obs_var = 0.0977\n",
      "Iter 5600, lower bound = -34.6815, obs_var = 0.0978\n",
      "Iter 5800, lower bound = -34.5841, obs_var = 0.0981\n",
      "Iter 6000, lower bound = -49.7580, obs_var = 0.0975\n",
      "Iter 6200, lower bound = -47.1258, obs_var = 0.0983\n",
      "Iter 6400, lower bound = -46.3451, obs_var = 0.0974\n",
      "Iter 6600, lower bound = -37.1923, obs_var = 0.0974\n",
      "Iter 6800, lower bound = -39.6809, obs_var = 0.0975\n",
      "Iter 7000, lower bound = -46.5636, obs_var = 0.0976\n",
      "Iter 7200, lower bound = -54.3121, obs_var = 0.0971\n",
      "Iter 7400, lower bound = -48.7697, obs_var = 0.0979\n",
      "Iter 7600, lower bound = -37.3892, obs_var = 0.0978\n",
      "Iter 7800, lower bound = -44.7906, obs_var = 0.0970\n",
      "Iter 8000, lower bound = -47.4180, obs_var = 0.0975\n",
      "Iter 8200, lower bound = -49.9600, obs_var = 0.0974\n",
      "Iter 8400, lower bound = -36.5243, obs_var = 0.0974\n",
      "Iter 8600, lower bound = -38.1591, obs_var = 0.0972\n",
      "Iter 8800, lower bound = -29.5193, obs_var = 0.0970\n",
      "Iter 9000, lower bound = -49.2770, obs_var = 0.0974\n",
      "Iter 9200, lower bound = -53.6488, obs_var = 0.0972\n",
      "Iter 9400, lower bound = -49.6055, obs_var = 0.0968\n",
      "Iter 9600, lower bound = -59.2174, obs_var = 0.0964\n",
      "Iter 9800, lower bound = -29.3342, obs_var = 0.0972\n",
      "Iter 10000, lower bound = -57.7911, obs_var = 0.0962\n"
     ]
    }
   ],
   "source": [
    "save_iters = [100*i + 1 for i in range(n_iters // 100)]\n",
    "\n",
    "for t in range(1, n_iters + 1):\n",
    "    if t in save_iters:\n",
    "        print(\"Saving figures...\")\n",
    "        save_figures(t)\n",
    "\n",
    "    _, train_ll, obs_var = sess.run(\n",
    "        [infer_op, obj, likelihood_var],\n",
    "        feed_dict=feed_dict)\n",
    "    if t % 200 == 0:\n",
    "        print(\"Iter {}, lower bound = {:.4f}, obs_var = {:.4f}\"\n",
    "              .format(t, -train_ll, obs_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate the animation from saved figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "9KBWOaZdyKXd",
    "outputId": "14f2a23f-6ed4-43aa-f7db-b2b2b345b7d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  45%|████▌     | 23/51 [00:00<00:00, 226.64it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video results/movie.mp4.\n",
      "Moviepy - Writing video results/movie.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready results/movie.mp4\n"
     ]
    }
   ],
   "source": [
    "filenames = [os.path.join(\"results\", \"solvegp-iter-{}.png\".format(i)) for i in range(1, 5002, 100)]\n",
    "\n",
    "with imageio.get_writer(os.path.join(\"results\", 'movie.gif'), mode='I', duration=0.2) as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "\n",
    "clip = mp.VideoFileClip(os.path.join(\"results\", 'movie.gif'))\n",
    "clip.write_videofile(os.path.join(\"results\", 'movie.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "solvegp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
